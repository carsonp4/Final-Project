{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d11b2c7",
   "metadata": {},
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c489c940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import re\n",
    "import requests\n",
    "import urllib.parse\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5662f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this just to see more of the dataframe\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ee77ca",
   "metadata": {},
   "source": [
    "Getting Awards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0819283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the 20 awards I wanted to scarpe, only 12 of them worked with this code \n",
    "# so we will work with that for this project but more work in the future would be great\n",
    "guilds = [\"ev0000003\", #Oscars\n",
    "          \"ev0000123\", #Baftas\n",
    "          #\"ev0000298\", #Gothams\n",
    "          \"ev0000292\", # Golden Globes\n",
    "          #\"ev0000133\", # Critics Choice\n",
    "          \"ev0000349\", #spirit\n",
    "          #\"ev0000147\", # Cannes\n",
    "          #\"ev0000681\", # Venice\n",
    "          \"ev0000631\", # Sundance\n",
    "          \"ev0000598\", #SAG\n",
    "          \"ev0000212\", #DGA\n",
    "          #\"ev0000531\", #PGA\n",
    "          \"ev0000618\", #ADG\n",
    "          \"ev0000175\", #CAS\n",
    "          #\"ev0000327\", #MUAH\n",
    "          \"ev0000022\", #ASC\n",
    "          #\"ev0000864\", #VES\n",
    "          #\"ev0004323\", #GMS\n",
    "          \"ev0000017\", #Eddies\n",
    "          \"ev0000710\" #WGA\n",
    "    ]\n",
    "all_awards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "354bbbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320ebaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(len(guilds)):\n",
    "    \n",
    "    # Just going to scrape 21st century awards\n",
    "    years_list = [str(year) for year in range(2000, 2024)]\n",
    "    \n",
    "    for k in range(len(years_list)):\n",
    "        \n",
    "        # Open the driver to the appropriate link\n",
    "        url = \"https://www.imdb.com/event/\" + guilds[l] + \"/\" + years_list[k]\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Blank dataframe to fill in for each award\n",
    "        ceremony = pd.DataFrame({'year': [''] * 1000, 'ceremony': [''] * 1000, 'award': [''] * 1000, 'id1': [''] * 1000, 'nom1': [''] * 1000, 'id2': [''] * 1000, 'nom2': [''] * 1000, 'id3': [''] * 1000, 'nom3': [''] * 1000, 'id4': [''] * 1000, 'nom4': [''] * 1000, 'nominated': [''] * 1000, 'winner': [''] * 1000})\n",
    "        \n",
    "        # Access the part of the page with the elements we want to scrape\n",
    "        container = driver.find_elements(By.CLASS_NAME, 'event-widgets__award')[0]\n",
    "        awards = container.find_elements(By.XPATH, \".//div[@class='event-widgets__award-category']\")\n",
    "        \n",
    "        # Running row number to fill in the dataframe\n",
    "        row = 0\n",
    "        for j in range(len(awards)):\n",
    "            \n",
    "            # Select one of the awards from the page\n",
    "            cur_award = awards[j]\n",
    "            \n",
    "            # Select the nominees from that award\n",
    "            cur_noms = cur_award.find_elements(By.XPATH, \".//div[contains(@class, 'event-widgets__award-nomination')]\")\n",
    "            \n",
    "            for i in range(len(cur_noms)):\n",
    "                \n",
    "                # Access certain easy to get data points\n",
    "                ceremony[\"year\"][i + row] = driver.find_element(By.CLASS_NAME, 'event-year-header__year').text\n",
    "                ceremony[\"ceremony\"][i + row] = driver.find_element(By.CLASS_NAME, 'event-widgets__award-name').text\n",
    "                ceremony[\"award\"][i + row] = cur_award.find_element(By.XPATH, \".//div[@class='event-widgets__award-category-name']\").text\n",
    "                \n",
    "                # This next large chunk of code gets all of the links from each award section and copies them\n",
    "                # So we can have each movie's ID later on\n",
    "                link_elements = cur_noms[i].find_elements(By.XPATH, \".//a\")\n",
    "                if len(link_elements) >=1:\n",
    "                    link = link_elements[0].get_attribute(\"href\")\n",
    "                    match = re.search(r'/([a-z]+)(\\d+)/', link)\n",
    "                    if match:\n",
    "                        nom_prefix = match.group(1)\n",
    "                        nom_id = match.group(2)\n",
    "                        ceremony[\"id1\"][i + row] = nom_prefix + nom_id\n",
    "                if len(link_elements) >=2:\n",
    "                    link = link_elements[1].get_attribute(\"href\")\n",
    "                    match = re.search(r'/([a-z]+)(\\d+)/', link)\n",
    "                    if match:\n",
    "                        nom_prefix = match.group(1)\n",
    "                        nom_id = match.group(2)\n",
    "                        ceremony[\"id2\"][i + row] = nom_prefix + nom_id\n",
    "                if len(link_elements) >=3:\n",
    "                    link = link_elements[2].get_attribute(\"href\")\n",
    "                    match = re.search(r'/([a-z]+)(\\d+)/', link)\n",
    "                    if match:\n",
    "                        nom_prefix = match.group(1)\n",
    "                        nom_id = match.group(2)\n",
    "                        ceremony[\"id3\"][i + row] = nom_prefix + nom_id\n",
    "                if len(link_elements) >=4:\n",
    "                    link = link_elements[3].get_attribute(\"href\")\n",
    "                    match = re.search(r'/([a-z]+)(\\d+)/', link)\n",
    "                    if match:\n",
    "                        nom_prefix = match.group(1)\n",
    "                        nom_id = match.group(2)\n",
    "                        ceremony[\"id4\"][i + row] = nom_prefix + nom_id\n",
    "                nominees_elements = cur_noms[i].find_elements(By.XPATH, \".//a\")\n",
    "                if len(nominees_elements) >= 1:\n",
    "                    ceremony[\"nom1\"][i + row] = nominees_elements[0].text\n",
    "                if len(nominees_elements) >= 2:\n",
    "                    ceremony[\"nom2\"][i + row] = nominees_elements[1].text\n",
    "                if len(nominees_elements) >= 3:\n",
    "                    ceremony[\"nom3\"][i + row] = nominees_elements[2].text\n",
    "                if len(nominees_elements) >= 4:\n",
    "                    ceremony[\"nom4\"][i + row] = nominees_elements[3].text\n",
    "                \n",
    "                # Marks that they were nominated and if they won\n",
    "                ceremony[\"nominated\"][i + row] = 1\n",
    "                ceremony[\"winner\"][i + row] = 1 if i == 0 else 0\n",
    "            \n",
    "            # Updates row number we are on in the dataframe\n",
    "            row += len(cur_noms)\n",
    "        \n",
    "        # Removes blank rows from dataframe\n",
    "        ceremony = ceremony.replace('', pd.NA).dropna(how='all').fillna('')\n",
    "        \n",
    "        # Adds this dataframe to a list of all the dataframes\n",
    "        all_awards.append(ceremony)\n",
    "        \n",
    "# Puts all of the dataframes together        \n",
    "all_awards = pd.concat(all_awards, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ab5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_awards.to_csv(\"all_awards.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c595c31",
   "metadata": {},
   "source": [
    "Remove all Non-Film Awards\n",
    "1. Tv Shows\n",
    "2. Shorts\n",
    "3. Exclusive awards (British, first films)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bd0646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the scraped awards data\n",
    "all_awards = pd.read_csv(\"all_awards.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d182f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a list of all the different awards that were scraped\n",
    "all_awards.groupby(['ceremony', 'award']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b57193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing different awards that aren't relevant to this analysis\n",
    "film_awards = all_awards[~all_awards['award'].str.contains('Tele|Serie|Short|Commer|Show|Event|Breakthrough|Current|Music Video|British|Children|Daytime|Special Award|Student|Debut|First|Non-The|Under|Pilot|DVD|Reality|Musical|Talk|Variety Special', case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb17708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This large chunk of code is from going through each of the awards and simplyfying the titles. Each award\n",
    "# is now uniformily named\n",
    "\n",
    "Adapted_Screenplay = [\"Adapted Screenplay\", \"Best Adapted Screenplay\", \"Best Screenplay (Adapted)\", \"Best Screenplay - Adapted\", \"Best Screenplay Based on Material Previously Produced or Published\", \"Best Writing, Adapted Screenplay\", \"Best Writing, Screenplay Based on Material Previously Produced or Published\"]\n",
    "Animated = [\"Animated Film\", \"Best Animated Feature\", \"Best Animated Feature Film\", \"Best Animated Feature Film of the Year\", \"Best Animated Featured Film\", \"Best Animated Film\", \"Best Motion Picture - Animated\", \"Outstanding Achievement in Sound Mixing for Motion Pictures - Animated\"]\n",
    "Art_Direction = [\"Best Achievement in Art Direction\", \"Best Art Direction-Set Decoration\"]\n",
    "Casting = [\"Best Casting\", \"Outstanding Performance by a Cast in a Motion Picture\", \"Outstanding Performance by a Cast in a Theatrical Motion Picture\", \"Outstanding Performance by the Cast of a Theatrical Motion Picture\"]\n",
    "Cinematography = [\"Best Achievement in Cinematography\", \"Best Cinematography\"]\n",
    "Costume_Design = [\"Best Achievement in Costume Design\", \"Best Costume Design\"]\n",
    "Directing = [\"Best Achievement in Directing\", \"Best Director\", \"Best Director - Motion Picture\"]\n",
    "Documentary = [\"Best Documentary\", \"Best Documentary Feature\", \"Best Documentary Film\", \"Best Documentary, Feature\", \"Best Documentary, Features\", \"Documentary\", \"Outstanding Achievement in Cinematography in Documentary Film\", \"Outstanding Achievement in Cinematography in Non-Fiction Filmmaking\", \"Outstanding Achievement in Sound Mixing for Motion Pictures - Documentary\", \"Outstanding Directorial Achievement in Documentary\", \"World Cinema - Documentary\"]\n",
    "Documentary_Screenplay = [\"Best Documentary Screenplay\", \"Documentary Screenplay\"]\n",
    "Editing = [\"Best Achievement in Film Editing\", \"Best Edited Feature Film - Comedy\", \"Best Edited Feature Film - Dramatic\", \"Best Editing\", \"Best Film Editing\"]\n",
    "Edited_Animated = [\"Best Edited Animated Feature Film\"]\n",
    "Edited_Documentary = [\"Best Edited Documentary\", \"Best Edited Documentary - Feature\", \"Best Edited Documentary - Theatrical\", \"Best Edited Documentary Film\"]\n",
    "Film = [\"Best Feature\", \"Best Film\", \"Best Motion Picture - Drama\", \"Best Motion Picture of the Year\", \"Best Picture\", \"Contemporary Film\", \"Dramatic\", \"Fantasy Film\", \"Feature Film\", \"Outstanding Achievement in Cinematography in Feature Film\", \"Outstanding Achievement in Cinematography in Theatrical Feature Film\", \"Outstanding Achievement in Cinematography in Theatrical Releases\", \"Outstanding Achievement in Sound Mixing for Motion Pictures\", \"Outstanding Achievement in Sound Mixing for Motion Pictures - Live Action\", \"Outstanding Achievement in Sound Mixing for a Feature Film\", \"Outstanding Directorial Achievement in Feature Film\", \"Outstanding Directorial Achievement in Motion Pictures\", \"Outstanding Directorial Achievement in Theatrical Feature Film\", \"Period Film\", \"Period or Fantasy Film\", \"World Cinema - Dramatic\"]\n",
    "International = [\"Best Foreign Film\",  \"Best International Feature Film\", \"Best International Film\"]\n",
    "Makeup_Hair = [\"Best Achievement in Makeup\", \"Best Achievement in Makeup and Hairstyling\", \"Best Make Up & Hair\", \"Best Make Up/Hair\", \"Best Makeup\", \"Best Makeup and Hair\"]\n",
    "Non_English = [\"Best Film Not in the English Language\", \"Best Film not in the English Language\", \"Best Foreign Language Film\", \"Best Foreign Language Film of the Year\", \"Best Motion Picture - Foreign Language\", \"Best Motion Picture - Non-English Language\"]\n",
    "Orignial_Screenplay = [\"Best Original Screenplay\", \"Best Screenplay (Original)\", \"Best Screenplay - Original\", \"Best Screenplay Written Directly for the Screen\", \"Best Writing, Original Screenplay\", \"Best Writing, Screenplay Written Directly for the Screen\", \"Original Screenplay\"]\n",
    "Score = [\"Best Achievement in Music Written for Motion Pictures (Original Score)\", \"Best Achievement in Music Written for Motion Pictures, Original Score\", \"Best Music, Original Score\", \"Best Original Music\", \"Best Original Score - Motion Picture\", \"Original Music\", \"Original Score\"]\n",
    "Screenplay = [\"Best Screenplay\", \"Best Screenplay - Motion Picture\"]\n",
    "Song = [\"Best Achievement in Music Written for Motion Pictures (Original Song)\", \"Best Achievement in Music Written for Motion Pictures, Original Song\", \"Best Music, Original Song\", \"Best Original Song - Motion Picture\"]\n",
    "Sound = [\"Best Achievement in Sound Editing\", \"Best Achievement in Sound Mixing\", \"Best Sound\", \"Best Sound Editing\", \"Best Sound Mixing\", \"Outstanding Sound Mixing for Motion Pictures\"]\n",
    "Sound_Effects = [\"Best Effects, Sound Effects Editing\"]\n",
    "Stunt = [\"Outstanding Action Performance by a Stunt Ensemble in a Motion Picture\", \"Outstanding Performance by a Stunt Ensemble in a Motion Picture\"]\n",
    "Production_Design = [\"Best Achievement in Production Design\", \"Best Production Design\", \"Best Production Design/Art Direction\"]\n",
    "Visual_Effects = [\"Best Achievement in Special Visual Effects\", \"Best Achievement in Visual Effects\", \"Best Effects, Visual Effects\", \"Best Special Visual Effects\", \"Best Visual Effects\"]\n",
    "\n",
    "Lead = [\"Best Lead Performance\"]\n",
    "Support = [\"Best Supporting Performance\"]\n",
    "Lead_Actor = [\"Best Actor in a Leading Role\", \"Best Leading Actor\", \"Best Male Lead\", \"Best Performance by an Actor in a Leading Role\", \"Best Performance by an Actor in a Motion Picture - Drama\", \"Outstanding Performance by a Male Actor in a Leading Role\"]\n",
    "Support_Actor = [\"Best Actor in a Supporting Role\", \"Best Performance by an Actor in a Supporting Role\", \"Best Performance by an Actor in a Supporting Role in Any Motion Picture\", \"Best Performance by an Actor in a Supporting Role in a Motion Picture\", \"Best Supporting Actor\", \"Best Supporting Male\", \"Outstanding Performance by a Male Actor in a Supporting Role\"]\n",
    "Lead_Actress = [\"Best Actress in a Leading Role\", \"Best Female Lead\", \"Best Leading Actress\", \"Best Performance by an Actress in a Leading Role\", \"Best Performance by an Actress in a Motion Picture - Drama\", \"Outstanding Performance by a Female Actor in a Leading Role\"]\n",
    "Support_Actress = [\"Best Actress in a Supporting Role\", \"Best Performance by an Actress in a Supporting Role\", \"Best Performance by an Actress in a Supporting Role in Any Motion Picture\", \"Best Performance by an Actress in a Supporting Role in a Motion Picture\", \"Best Supporting Actress\", \"Best Supporting Female\", \"Outstanding Performance by a Female Actor in a Supporting Role\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0fd256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a dictionary of the different awards from the work above\n",
    "\n",
    "award_mapping = {\n",
    "    \"Adapted_Screenplay\": Adapted_Screenplay,\n",
    "    \"Animated\": Animated,\n",
    "    \"Art_Direction\": Art_Direction,\n",
    "    \"Casting\": Casting,\n",
    "    \"Cinematography\": Cinematography,\n",
    "    \"Costume_Design\": Costume_Design,\n",
    "    \"Directing\": Directing,\n",
    "    \"Documentary\": Documentary,\n",
    "    \"Documentary_Screenplay\": Documentary_Screenplay,\n",
    "    \"Editing\": Editing,\n",
    "    \"Edited_Animated\": Edited_Animated,\n",
    "    \"Edited_Documentary\": Edited_Documentary,\n",
    "    \"Film\": Film,\n",
    "    \"International\": International,\n",
    "    \"Makeup_Hair\": Makeup_Hair,\n",
    "    \"Non_English\": Non_English,\n",
    "    \"Orignial_Screenplay\": Orignial_Screenplay,\n",
    "    \"Score\": Score,\n",
    "    \"Screenplay\": Screenplay,\n",
    "    \"Song\": Song,\n",
    "    \"Sound\": Sound,\n",
    "    \"Sound_Effects\": Sound_Effects,\n",
    "    \"Stunt\": Stunt,\n",
    "    \"Production_Design\": Production_Design,\n",
    "    \"Visual_Effects\": Visual_Effects,\n",
    "    \"Lead\": Lead,\n",
    "    \"Support\": Support,\n",
    "    \"Lead_Actor\": Lead_Actor,\n",
    "    \"Support_Actor\": Support_Actor,\n",
    "    \"Lead_Actress\": Lead_Actress,\n",
    "    \"Support_Actress\": Support_Actress\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c548419",
   "metadata": {},
   "outputs": [],
   "source": [
    "for new_value, old_values in award_mapping.items():\n",
    "    film_awards['award'] = film_awards['award'].replace(old_values, new_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27faa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A couple of films didn't get their id copied. Mostly due to PGA wanting to give credit to like 10 producers\n",
    "\n",
    "film_awards.at[8300, 'id2'] = \"tt0243017\"\n",
    "film_awards.at[8301, 'id2'] = \"tt0248845\"\n",
    "film_awards.at[8302, 'id2'] = \"tt0245501\"\n",
    "film_awards.at[8303, 'id2'] = \"tt0242587\"\n",
    "film_awards.at[8351, 'id2'] = \"tt0282864\"\n",
    "film_awards.at[8353, 'id2'] = \"tt0274622\"\n",
    "film_awards.at[12774, 'id2'] = \"tt0169547\"\n",
    "film_awards = film_awards.drop(12810)\n",
    "film_awards.at[12819, 'id2'] = \"tt0190332\"\n",
    "film_awards.at[12834, 'id2'] = \"tt0268978\"\n",
    "film_awards.at[12912, 'id2'] = \"tt0299658\"\n",
    "film_awards.at[12958, 'id2'] = \"tt0167260\"\n",
    "film_awards.at[13006, 'id2'] = \"tt0405159\"\n",
    "film_awards.at[13050, 'id2'] = \"tt0388795\"\n",
    "film_awards.at[13379, 'id2'] = \"tt1024648\"\n",
    "film_awards.at[13469, 'id2'] = \"tt1454468\"\n",
    "film_awards.at[13519, 'id2'] = \"tt2562232\"\n",
    "film_awards.at[13559, 'id2'] = \"tt1663202\"\n",
    "film_awards.at[13563, 'id2'] = \"tt1895587\"\n",
    "film_awards.at[13679, 'id2'] = \"tt5580390\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da33006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a column of all the film id's\n",
    "film_awards['tt_values'] = film_awards.apply(lambda row: list(set([value for value in row if isinstance(value, str) and value.startswith('tt')])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0dcc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the film_id from each movie\n",
    "film_awards['film_id'] = film_awards['tt_values'].apply(lambda x: x[0] if x else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa9333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting all the columns we want to use now\n",
    "clean_df = film_awards[[\"year\", \"ceremony\",\"award\", \"nominated\", \"winner\", \"film_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ffda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the year varuable to just be the year digits\n",
    "clean_df['year'] = clean_df['year'].str.extract('(\\d+)', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5643f806",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Renamng the award names to be more reader friendly\n",
    "clean_df['ceremony'] = clean_df['ceremony'].replace('BAFTA Film Award', 'BAFTA')\n",
    "clean_df['ceremony'] = clean_df['ceremony'].replace('Golden Globe', 'GG')\n",
    "clean_df['ceremony'] = clean_df['ceremony'].replace('Independent Spirit Award', 'Spirit')\n",
    "clean_df['ceremony'] = clean_df['ceremony'].replace('Grand Jury Prize', 'Sundance')\n",
    "clean_df['ceremony'] = clean_df['ceremony'].replace('Actor', 'SAG')\n",
    "clean_df['ceremony'] = clean_df['ceremony'].replace('DGA Award', 'DGA')\n",
    "clean_df['ceremony'] = clean_df['ceremony'].replace('Excellence in Production Design Award', 'ADG')\n",
    "clean_df['ceremony'] = clean_df['ceremony'].replace('C.A.S. Award', 'CAS')\n",
    "clean_df['ceremony'] = clean_df['ceremony'].replace('ASC Award', 'ASC')\n",
    "clean_df['ceremony'] = clean_df['ceremony'].replace('WGA Award (Screen)', 'WGA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba2097b",
   "metadata": {},
   "source": [
    "Pivoting The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bb2787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for each combination of ceremony, award, and nominee\n",
    "df_nominated = clean_df.pivot_table(index=['film_id', 'year'], columns=['ceremony', 'award'], values='nominated', aggfunc='max', fill_value=0)\n",
    "\n",
    "# Create a new column for each combination of ceremony, award, and winner\n",
    "df_winner = clean_df.pivot_table(index=['film_id', 'year'], columns=['ceremony', 'award'], values='winner', aggfunc='max', fill_value=0)\n",
    "\n",
    "# Adding nominated and winner tags to the columns\n",
    "df_nominated.columns = [f'{col}_nominated' for col in df_nominated.columns]\n",
    "df_winner.columns = [f'{col}_winner' for col in df_winner.columns]\n",
    "\n",
    "# Concatenate the DataFrames along the columns\n",
    "result_df = pd.concat([df_nominated, df_winner], axis=1)\n",
    "\n",
    "# Reset the index to make film_id and year regular columns\n",
    "result_df.reset_index(inplace=True)\n",
    "\n",
    "# Fill NaN values with 0 (if any)\n",
    "result_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46546306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all columns from 2 onwards to numeric\n",
    "result_df.iloc[:, 2:] = result_df.iloc[:, 2:].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Group by 'film_id' and select the maximum value for 'year' and sum for other columns\n",
    "agg_dict = {col: 'sum' for col in result_df.columns[2:]}\n",
    "agg_dict['year'] = 'max'\n",
    "result_df = result_df.groupby('film_id', as_index=False).agg(agg_dict)\n",
    "\n",
    "# Reorder columns to have 'year' as the second column\n",
    "column_order = ['film_id', 'year'] + [col for col in result_df.columns if col not in ['film_id', 'year']]\n",
    "result_df = result_df[column_order]\n",
    "result_df = result_df.rename(columns={'year': 'award_year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3691909",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"result_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9618630d",
   "metadata": {},
   "source": [
    "Regression Fun With Just Awards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25575c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying Data\n",
    "reg = pd.read_csv(\"result_df.csv\")\n",
    "reg = reg.drop(reg.columns[0], axis=1)\n",
    "reg.set_index('film_id', inplace=True)\n",
    "\n",
    "\n",
    "# Removing oscar winners and using other awards as predictor variables\n",
    "columns_to_drop = [col for col in reg.columns if 'Oscar' in col and 'winner' in col]\n",
    "x = reg.drop(columns=columns_to_drop)\n",
    "\n",
    "#Seperating Out Oscar Best Picture as response variable\n",
    "y = reg[[\"award_year\", \"('Oscar', 'Film')_winner\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f66b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating test and training set of 2023\n",
    "X_train = x[x[\"award_year\"] != 2023]\n",
    "X_test = x[x[\"award_year\"] == 2023]\n",
    "y_train = y[y[\"award_year\"] != 2023]\n",
    "y_test = y[y[\"award_year\"] == 2023]\n",
    "\n",
    "X_train.drop(columns=[\"award_year\"], inplace=True)\n",
    "X_test.drop(columns=[\"award_year\"], inplace=True)\n",
    "y_train.drop(columns=[\"award_year\"], inplace=True)\n",
    "y_test.drop(columns=[\"award_year\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1601f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Logistic Regression Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f683f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Model Predictions and Probabilities\n",
    "y_pred = model.predict(X_test)\n",
    "y_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Get Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy is {accuracy}\")\n",
    "\n",
    "# Get Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Make ROC curve Plot\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Make Dataframe of Predctions\n",
    "probs_df = pd.DataFrame(data={'predicted_probabilities': y_probs}, index=y_test.index)\n",
    "pd.concat([y_test, probs_df], axis=1).sort_values(by='predicted_probabilities', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd3411",
   "metadata": {},
   "source": [
    "Web Scraping More Info. This code works but IMDB slows down when you try to scrape so ultimately did not use this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Dataframe of columns to populate\n",
    "movies_columns = [\"Title\", \"Rating\", \"IMDB\", \"Metascore\", \"Noms\", \"Director\", \"Writer\", \n",
    "           \"Release\", \"Country\", \"Language\", \"Budget\", \"Boxoffice\", \n",
    "           \"Runtime\", \"Color\", \"Aspect\"]\n",
    "\n",
    "# Creating a new DataFrame with blank columns and the same index as result_df\n",
    "movies = pd.DataFrame(index=result_df.index, columns=movies_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b5eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(movies)), desc=\"Processing\"):\n",
    "    \n",
    "    # Open the driver to the appropriate link\n",
    "    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "    url = \"https://www.imdb.com/title/\" + movies[\"film_id\"][i]\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Getting the Movie Title\n",
    "    movies[\"Title\"][i] = driver.find_element(By.XPATH, '//h1[contains(@data-testid, \"hero__pageTitle\")]').text\n",
    "    \n",
    "    # Getting the Parent Rating\n",
    "    parent = driver.find_elements(By.XPATH, '//a[contains(@href, \"/parentalguide/certificates\")]')\n",
    "    if len(parent) > 0:\n",
    "        movies[\"Rating\"][i] = parent[0].text\n",
    "    \n",
    "    # Getting IMDB Rating\n",
    "    imdbs = driver.find_elements(By.XPATH, '//div[contains(@data-testid, \"hero-rating-bar__aggregate-rating__score\")]')\n",
    "    imdb_text = ''\n",
    "    for j in range(len(imdbs)):\n",
    "        imdb_text += imdbs[j].text\n",
    "    movies[\"IMDB\"][i] = imdb_text\n",
    "    \n",
    "    # All the rest of values were convenintly marked with same \"presentation\" tag so we can make a list of \n",
    "    # these tags and then find the value afterwards\n",
    "    vals = driver.find_elements(By.XPATH, '//li[contains(@role, \"presentation\")]')\n",
    "    for z in range(len(vals)):\n",
    "        vals[z] = vals[z].text\n",
    "\n",
    "    movies[\"Metascore\"][i] = next((item for item in vals if \"Metascore\" in item), None)\n",
    "    movies[\"Noms\"][i] = next((item for item in vals if \"nominations\" in item), None)\n",
    "    movies[\"Director\"][i] = next((item for item in vals if \"Director\" in item), None)\n",
    "    movies[\"Writer\"][i] = next((item for item in vals if \"Writer\" in item), None)\n",
    "    movies[\"Release\"][i] = next((item for item in vals if \"Release date\\n\" in item), None)\n",
    "    movies[\"Country\"][i] = next((item for item in vals if \"of origin\\n\" in item), None)\n",
    "    movies[\"Language\"][i] = next((item for item in vals if \"Language\" in item), None)\n",
    "    movies[\"Budget\"][i] = next((item for item in vals if \"Budget\\n\" in item), None)\n",
    "    movies[\"Boxoffice\"][i] = next((item for item in vals if \"Gross worldwide\\n\" in item), None)\n",
    "    movies[\"Runtime\"][i] = next((item for item in vals if \"Runtime\\n\" in item), None)\n",
    "    movies[\"Color\"][i] = next((item for item in vals if \"Color\\n\" in item), None)\n",
    "    movies[\"Aspect\"][i] = next((item for item in vals if \"Aspect ratio\\n\" in item), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efb16b5",
   "metadata": {},
   "source": [
    "Using OMDB API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8efba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Dataframe of columns to populate\n",
    "movies_columns = [\"Title\", \"Rating\", \"Release\", \"Runtime\", \"Genre\", \"Director\", \"Writer\", \n",
    "                  \"Language\", \"Country\", \"Noms\", \"IMDB\", \"IMDB_Votes\", \"Rotten_Tomatoes\",\n",
    "                  \"Metascore\", \"Boxoffice\"]\n",
    "\n",
    "# Creating a new DataFrame with blank columns and the same index as result_df\n",
    "movies = pd.DataFrame(index=result_df[\"film_id\"], columns=movies_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baf9f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(movies)), desc=\"Processing\"):\n",
    "    \n",
    "    # Creating the API request url\n",
    "    base_url = \"http://www.omdbapi.com/\"\n",
    "    movie_id = \"?i=\" + movies.index[i]\n",
    "    apikey = \"&apikey=\" # + API KEY\n",
    "    url = base_url + movie_id + apikey\n",
    "\n",
    "    # Requesting the data and making a json file\n",
    "    response = requests.get(url)\n",
    "    data = response.json() \n",
    "    \n",
    "    #Populating the dataframe with the appropriate values\n",
    "    movies[\"Title\"][i] = data[\"Title\"]\n",
    "    movies[\"Rating\"][i] = data[\"Rated\"]\n",
    "    movies[\"Release\"][i] = data[\"Released\"]\n",
    "    movies[\"Runtime\"][i] = data[\"Runtime\"]\n",
    "    movies[\"Genre\"][i] = data[\"Genre\"]\n",
    "    movies[\"Director\"][i] = data[\"Director\"]\n",
    "    movies[\"Writer\"][i] = data[\"Writer\"]\n",
    "    movies[\"Language\"][i] = data[\"Language\"]\n",
    "    movies[\"Country\"][i] = data[\"Country\"]\n",
    "    movies[\"Noms\"][i] = data[\"Awards\"]\n",
    "    movies[\"IMDB\"][i] = data[\"imdbRating\"]\n",
    "    movies[\"IMDB_Votes\"][i] = data[\"imdbVotes\"]\n",
    "    movies[\"Rotten_Tomatoes\"][i] = data[\"Ratings\"][1][\"Value\"] if len(data[\"Ratings\"]) >= 2 else None\n",
    "    movies[\"Metascore\"][i] = data[\"Metascore\"]\n",
    "    movies[\"Boxoffice\"][i] = data[\"BoxOffice\"] if \"BoxOffice\" in data else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee016ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.to_csv(\"movies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdc9dfa",
   "metadata": {},
   "source": [
    "Cleaning Up API Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12c25de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new dataframe to edit\n",
    "apidf = pd.read_csv(\"movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ebb976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engenieering new date columns that could be helpful\n",
    "apidf['Release'] = pd.to_datetime(apidf['Release'], format='%d %b %Y')\n",
    "apidf['Release_Month'] = apidf['Release'].dt.month\n",
    "apidf['Release_Year'] = apidf['Release'].dt.year\n",
    "apidf['Release_DOY'] = apidf['Release'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a089d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertign Runtime to numeric\n",
    "apidf['Runtime'] = apidf['Runtime'].str.extract('(\\d+)').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b842f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making dummy variables for Parent Rating\n",
    "apidf['Rating'].fillna('Unknown', inplace=True)\n",
    "apidf = apidf.assign(Rating=apidf['Rating'].str.split(', ')).explode('Rating')\n",
    "Rating_indicators = pd.get_dummies(apidf['Rating'], prefix='Rating')\n",
    "apidf = pd.concat([apidf, Rating_indicators], axis=1)\n",
    "apidf.drop(columns=['Rating'], inplace=True)\n",
    "Rating_columns = apidf.columns[apidf.columns.str.startswith('Rating')]\n",
    "apidf[Rating_columns] = apidf.groupby(apidf.index)[Rating_columns].transform('sum')\n",
    "apidf.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27018fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making dummy variables for Genres\n",
    "apidf['Genre'].fillna('Unknown', inplace=True)\n",
    "apidf = apidf.assign(Genre=apidf['Genre'].str.split(', ')).explode('Genre')\n",
    "genre_indicators = pd.get_dummies(apidf['Genre'], prefix='Genre')\n",
    "apidf = pd.concat([apidf, genre_indicators], axis=1)\n",
    "apidf.drop(columns=['Genre'], inplace=True)\n",
    "genre_columns = apidf.columns[apidf.columns.str.startswith('Genre')]\n",
    "apidf[genre_columns] = apidf.groupby(apidf.index)[genre_columns].transform('sum')\n",
    "apidf.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bb1d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making dummy variables for Directors\n",
    "apidf['Director'].fillna('Unknown', inplace=True)\n",
    "apidf = apidf.assign(Director=apidf['Director'].str.split(', ')).explode('Director')\n",
    "Director_indicators = pd.get_dummies(apidf['Director'], prefix='Director')\n",
    "apidf = pd.concat([apidf, Director_indicators], axis=1)\n",
    "apidf.drop(columns=['Director'], inplace=True)\n",
    "Director_columns = apidf.columns[apidf.columns.str.startswith('Director')]\n",
    "apidf[Director_columns] = apidf.groupby(apidf.index)[Director_columns].transform('sum')\n",
    "apidf.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4af8af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making dummy variables for Writers\n",
    "apidf['Writer'].fillna('Unknown', inplace=True)\n",
    "apidf = apidf.assign(Writer=apidf['Writer'].str.split(', ')).explode('Writer')\n",
    "Writer_indicators = pd.get_dummies(apidf['Writer'], prefix='Writer')\n",
    "apidf = pd.concat([apidf, Writer_indicators], axis=1)\n",
    "apidf.drop(columns=['Writer'], inplace=True)\n",
    "Writer_columns = apidf.columns[apidf.columns.str.startswith('Writer')]\n",
    "apidf[Writer_columns] = apidf.groupby(apidf.index)[Writer_columns].transform('sum')\n",
    "apidf.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4ec9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making dummy variables for Languages\n",
    "apidf['Language'].fillna('Unknown', inplace=True)\n",
    "apidf = apidf.assign(Language=apidf['Language'].str.split(', ')).explode('Language')\n",
    "Language_indicators = pd.get_dummies(apidf['Language'], prefix='Language')\n",
    "apidf = pd.concat([apidf, Language_indicators], axis=1)\n",
    "apidf.drop(columns=['Language'], inplace=True)\n",
    "Language_columns = apidf.columns[apidf.columns.str.startswith('Language')]\n",
    "apidf[Language_columns] = apidf.groupby(apidf.index)[Language_columns].transform('sum')\n",
    "apidf.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ab1b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making dummy variables for Countries\n",
    "apidf['Country'].fillna('Unknown', inplace=True)\n",
    "apidf = apidf.assign(Country=apidf['Country'].str.split(', ')).explode('Country')\n",
    "Country_indicators = pd.get_dummies(apidf['Country'], prefix='Country')\n",
    "apidf = pd.concat([apidf, Country_indicators], axis=1)\n",
    "apidf.drop(columns=['Country'], inplace=True)\n",
    "Country_columns = apidf.columns[apidf.columns.str.startswith('Country')]\n",
    "apidf[Country_columns] = apidf.groupby(apidf.index)[Country_columns].transform('sum')\n",
    "apidf.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51efa3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engenieering the total wins and total nominations data\n",
    "apidf['Total_Wins'] = apidf['Noms'].str.extract('(\\d+) wins?').astype(float)\n",
    "apidf['Total_Noms'] = apidf['Noms'].str.extract('(\\d+) nominations?').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c1dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning different website rating values\n",
    "apidf['IMDB'] = apidf['IMDB'].astype(float)\n",
    "apidf['IMDB_Votes'] = apidf['IMDB_Votes'].str.replace(',', '').astype(float)\n",
    "apidf.loc[~apidf['Rotten_Tomatoes'].str.contains('%', na=False), 'Rotten_Tomatoes'] = 0\n",
    "apidf['Rotten_Tomatoes'] = apidf['Rotten_Tomatoes'].str.replace('%', '').astype(float)\n",
    "apidf['Metascore'] = apidf['Metascore'].astype(float)\n",
    "apidf['Boxoffice'] = apidf['Boxoffice'].str.replace(',', '').str.replace('$', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ffe6f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Resetting index\n",
    "apidf.set_index(['film_id', 'Title'], inplace=True)\n",
    "\n",
    "# Removing old columns\n",
    "apidf.drop(columns=[\"Release\", \"Noms\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4ca990",
   "metadata": {},
   "outputs": [],
   "source": [
    "apidf.to_csv(\"apidf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0bbc95",
   "metadata": {},
   "source": [
    "Make Master Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc32b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in two datasets to make Master Dataset\n",
    "apidf = pd.read_csv(\"apidf.csv\")\n",
    "resultdf = pd.read_csv(\"result_df.csv\")\n",
    "\n",
    "# Setting Index Columns To Merge On\n",
    "resultdf = resultdf.drop(resultdf.columns[0], axis=1)\n",
    "resultdf.set_index('film_id', inplace=True)\n",
    "apidf.set_index('film_id', inplace=True)\n",
    "\n",
    "# Merging two dataframe\n",
    "maindf = pd.merge(apidf, resultdf, left_index=True, right_index=True)\n",
    "\n",
    "# Setting Film Name as Index Column\n",
    "maindf.set_index(['Title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a7e02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "maindf.to_csv(\"maindf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc9f3a",
   "metadata": {},
   "source": [
    "Full Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26254aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying Data\n",
    "reg = pd.read_csv(\"maindf.csv\")\n",
    "reg.set_index('Title', inplace=True)\n",
    "\n",
    "# Create a SimpleImputer with strategy 'mean'\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Apply the imputer to your entire dataset\n",
    "reg = pd.DataFrame(imputer.fit_transform(reg), columns=reg.columns)\n",
    "\n",
    "# Set Index\n",
    "reg.set_index(maindf.index, inplace=True)\n",
    "\n",
    "\n",
    "# Removing oscar winners and using other awards as predictor variables\n",
    "columns_to_drop = [col for col in reg.columns if 'Oscar' in col and 'winner' in col]\n",
    "x = reg.drop(columns=columns_to_drop)\n",
    "\n",
    "#Seperating Out Oscar Best Picture as response variable\n",
    "y = reg[[\"award_year\", \"('Oscar', 'Film')_winner\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59b887e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating test and training set of 2023\n",
    "X_train = x[x[\"award_year\"] != 2023]\n",
    "X_test = x[x[\"award_year\"] == 2023]\n",
    "y_train = y[y[\"award_year\"] != 2023]\n",
    "y_test = y[y[\"award_year\"] == 2023]\n",
    "\n",
    "X_train.drop(columns=[\"award_year\"], inplace=True)\n",
    "X_test.drop(columns=[\"award_year\"], inplace=True)\n",
    "y_train.drop(columns=[\"award_year\"], inplace=True)\n",
    "y_test.drop(columns=[\"award_year\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b896a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Logistic Regression Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37f73a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Model Predictions and Probabilities\n",
    "y_pred = model.predict(X_test)\n",
    "y_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Get Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy is {accuracy}\")\n",
    "\n",
    "# Get Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Make ROC curve Plot\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Make Dataframe of Predctions\n",
    "probs_df = pd.DataFrame(data={'predicted_probabilities': y_probs}, index=y_test.index)\n",
    "pd.concat([y_test, probs_df], axis=1).sort_values(by='predicted_probabilities', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4f347c",
   "metadata": {},
   "source": [
    "Oscar Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae22c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "maindf = pd.read_csv(\"maindf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d41237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar_noms = maindf.loc[:, maindf.columns[maindf.columns.str.contains('Oscar') & maindf.columns.str.contains('nominated')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b079561",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar_noms.columns = oscar_noms.columns.map(lambda x: x.split(\"'\")[3] if isinstance(x, str) and 'Oscar' in x and '_nominated' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ecbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar_noms['International'] = oscar_noms['International'] + oscar_noms['Non_English']\n",
    "oscar_noms.drop(columns=[\"Non_English\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4c2735",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar_noms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caa9e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "correlation_matrix = oscar_noms.corr()\n",
    "\n",
    "# Create a heatmap using seaborn\n",
    "plt.figure(figsize=(15, 12))\n",
    "heatmap = sns.heatmap(correlation_matrix, annot=True, cmap='RdYlBu', fmt='.2f', linewidths=0.5, center=0)\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "plt.title('Correlation Of Films By Oscar Nomination', fontsize=16)\n",
    "plt.xlabel('Oscar Nomination Categories')\n",
    "plt.ylabel('Oscar Nomination Categories')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
